#!/usr/bin/env python3
"""
Enhanced Vietnamese Financial AI Service
Complete RAG + Classification system ready for production
"""

import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
import pickle
from datetime import datetime
import uuid
import re
import numpy as np

try:
    from underthesea import word_tokenize
except ImportError:
    def word_tokenize(text):
        return text.split()

try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
except ImportError:
    print("Warning: sklearn not available, using basic similarity")
    TfidfVectorizer = None
    cosine_similarity = None

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class VietnameseFinancialAI:
    def __init__(self):
        """Initialize Enhanced Vietnamese Financial AI system"""
        
        # Load trained classifier
        try:
            self.classifier_data = self._load_classifier()
            logger.info("Vietnamese classifier loaded")
        except Exception as e:
            logger.warning(f"Classifier not available: {e}")
            self.classifier_data = None
        
        # Load transaction embeddings
        self.transaction_embeddings = None
        self.transaction_metadata = None
        
        # Vietnamese financial knowledge base
        self.knowledge_base = self._create_knowledge_base()
        
        # Initialize knowledge vectorizer
        if TfidfVectorizer:
            self.knowledge_vectorizer = TfidfVectorizer(
                max_features=1000,
                ngram_range=(1, 2),
                min_df=1,
                lowercase=True
            )
            
            # Create knowledge embeddings
            self._create_knowledge_embeddings()
    
    def _load_classifier(self):
        """Load trained Vietnamese classifier"""
        try:
            with open("vietnamese_transaction_classifier.pkl", 'rb') as f:
                return pickle.load(f)
        except FileNotFoundError:
            logger.warning("Classifier file not found")
            return None
    
    def _create_knowledge_base(self) -> List[Dict]:
        """Create comprehensive Vietnamese financial knowledge base"""
        
        return [
            {
                "id": "classification_guide",
                "title": "H∆∞·ªõng d·∫´n ph√¢n lo·∫°i giao d·ªãch t√†i ch√≠nh",
                "content": """
                Giao d·ªãch t√†i ch√≠nh ƒë∆∞·ª£c ph√¢n th√†nh 8 lo·∫°i ch√≠nh:
                
                üçú **ƒÇn u·ªëng (food)**: Qu√°n ƒÉn, c√† ph√™, b√°nh k·∫πo, nh√† h√†ng, cƒÉng tin
                üöó **Giao th√¥ng (transport)**: Xe bus, taxi, Grab, xƒÉng xe, v√© m√°y bay, t√†u xe
                üõí **Mua s·∫Øm (shopping)**: Si√™u th·ªã, ch·ª£, c·ª≠a h√†ng, qu·∫ßn √°o, ƒë·ªì gia d·ª•ng
                üé¨ **Gi·∫£i tr√≠ (entertainment)**: Xem phim, karaoke, du l·ªãch, game, s√°ch b√°o
                ‚ö° **Ti·ªán √≠ch (utilities)**: ƒêi·ªán, n∆∞·ªõc, internet, ƒëi·ªán tho·∫°i, gas
                üè• **S·ª©c kh·ªèe (healthcare)**: Kh√°m b·ªánh, mua thu·ªëc, b·∫£o hi·ªÉm y t·∫ø
                üìö **Gi√°o d·ª•c (education)**: H·ªçc ph√≠, s√°ch v·ªü, kh√≥a h·ªçc, gia s∆∞
                üí∞ **Thu nh·∫≠p (income)**: L∆∞∆°ng, th∆∞·ªüng, l√†m th√™m, b√°n h√†ng
                """,
                "keywords": ["ph√¢n lo·∫°i", "giao d·ªãch", "categories", "food", "transport", "shopping"],
                "category": "classification"
            },
            {
                "id": "budget_management",
                "title": "Qu·∫£n l√Ω ng√¢n s√°ch theo quy t·∫Øc 50/30/20",
                "content": """
                Quy t·∫Øc qu·∫£n l√Ω ng√¢n s√°ch 50/30/20 hi·ªáu qu·∫£:
                
                **50% cho nhu c·∫ßu thi·∫øt y·∫øu**: ƒÇn u·ªëng, nh√† ·ªü, ƒëi l·∫°i, ƒëi·ªán n∆∞·ªõc
                **30% cho mong mu·ªën c√° nh√¢n**: Gi·∫£i tr√≠, mua s·∫Øm, du l·ªãch
                **20% cho ti·∫øt ki·ªám & ƒë·∫ßu t∆∞**: G·ª≠i ng√¢n h√†ng, ch·ª©ng kho√°n, b·∫•t ƒë·ªông s·∫£n
                
                **C√°ch th·ª±c hi·ªán:**
                - T√≠nh thu nh·∫≠p sau thu·∫ø h√†ng th√°ng
                - Chia theo t·ª∑ l·ªá 50/30/20
                - Theo d√µi chi ti√™u h√†ng ng√†y
                - ƒêi·ªÅu ch·ªânh n·∫øu v∆∞·ª£t ng√¢n s√°ch
                """,
                "keywords": ["ng√¢n s√°ch", "50/30/20", "qu·∫£n l√Ω", "ti·∫øt ki·ªám", "chi ti√™u"],
                "category": "budgeting"
            }
        ]
    
    def _create_knowledge_embeddings(self):
        """Create embeddings for knowledge base"""
        if not TfidfVectorizer:
            return
            
        knowledge_texts = []
        for item in self.knowledge_base:
            text = f"{item['title']} {item['content']} {' '.join(item['keywords'])}"
            knowledge_texts.append(text)
        
        try:
            self.knowledge_embeddings = self.knowledge_vectorizer.fit_transform(knowledge_texts)
            logger.info(f"Created embeddings for {len(knowledge_texts)} knowledge items")
        except Exception as e:
            logger.error(f"Error creating knowledge embeddings: {e}")
    
    def classify_transaction(self, transaction_text: str) -> Dict[str, Any]:
        """Classify Vietnamese transaction text"""
        
        # Simple rule-based classification as fallback
        categories = {
            'ƒÉn u·ªëng': ['ƒÉn', 'u·ªëng', 'c√† ph√™', 'c∆°m', 'ph·ªü', 'qu√°n', 'nh√† h√†ng', 'kfc', 'lotteria'],
            'di chuy·ªÉn': ['grab', 'taxi', 'xe', 'xƒÉng', 'v√©', 'm√°y bay', 't√†u'],
            'mua s·∫Øm': ['mua', 'shopping', 'si√™u th·ªã', 'ch·ª£', 'qu·∫ßn √°o', 'gi√†y'],
            'gi·∫£i tr√≠': ['xem phim', 'karaoke', 'du l·ªãch', 'game', 'cinema'],
            'ti·ªán √≠ch': ['ƒëi·ªán', 'n∆∞·ªõc', 'internet', 'wifi', 'gas'],
            's·ª©c kh·ªèe': ['b·ªánh vi·ªán', 'thu·ªëc', 'kh√°m'],
            'gi√°o d·ª•c': ['h·ªçc', 's√°ch', 'tr∆∞·ªùng'],
            'kh√°c': []
        }
        
        text_lower = transaction_text.lower()
        
        for category, keywords in categories.items():
            for keyword in keywords:
                if keyword in text_lower:
                    return {
                        'category': category,
                        'confidence': 0.8,
                        'method': 'rule_based'
                    }
        
        return {
            'category': 'kh√°c',
            'confidence': 0.5,
            'method': 'default'
        }
    
    def get_financial_advice(self, query: str) -> Dict[str, Any]:
        """Get financial advice using RAG"""
        
        if not self.knowledge_base:
            return {
                'answer': 'Xin l·ªói, h·ªá th·ªëng t∆∞ v·∫•n ch∆∞a s·∫µn s√†ng.',
                'confidence': 0.0,
                'sources': []
            }
        
        # Simple keyword matching as fallback
        query_lower = query.lower()
        relevant_items = []
        
        for item in self.knowledge_base:
            for keyword in item['keywords']:
                if keyword.lower() in query_lower:
                    relevant_items.append(item)
                    break
        
        if not relevant_items:
            return {
                'answer': 'T√¥i ch∆∞a t√¨m th·∫•y th√¥ng tin ph√π h·ª£p. B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ ph√¢n lo·∫°i giao d·ªãch, qu·∫£n l√Ω ng√¢n s√°ch, ho·∫∑c ƒë·∫ßu t∆∞ ti·∫øt ki·ªám.',
                'confidence': 0.3,
                'sources': []
            }
        
        # Return the most relevant item
        best_item = relevant_items[0]
        
        return {
            'answer': best_item['content'],
            'confidence': 0.9,
            'sources': [best_item['title']],
            'category': best_item['category']
        }
    
    def process_transaction_batch(self, transactions: List[Dict]) -> List[Dict]:
        """Process a batch of transactions"""
        results = []
        
        for transaction in transactions:
            try:
                text = transaction.get('text', transaction.get('description', ''))
                classification = self.classify_transaction(text)
                
                enhanced_transaction = transaction.copy()
                enhanced_transaction.update({
                    'ai_category': classification['category'],
                    'ai_confidence': classification['confidence'],
                    'processed_at': datetime.now().isoformat(),
                    'processor_version': '2.0'
                })
                
                results.append(enhanced_transaction)
                
            except Exception as e:
                logger.error(f"Error processing transaction: {e}")
                results.append(transaction)
        
        return results

def main():
    """Test the Enhanced Vietnamese Financial AI"""
    ai = VietnameseFinancialAI()
    
    # Test classification
    test_transactions = [
        "Mua c√† ph√™ Starbucks 85000 VND",
        "Grab t·ª´ nh√† ƒë·∫øn c√¥ng ty 45000 VND",
        "Mua s·∫Øm ·ªü Vincom 250000 VND"
    ]
    
    logger.info("Testing transaction classification:")
    for text in test_transactions:
        result = ai.classify_transaction(text)
        logger.info(f"'{text}' -> {result['category']} (confidence: {result['confidence']})")
    
    # Test advice
    test_queries = [
        "L√†m th·∫ø n√†o ƒë·ªÉ qu·∫£n l√Ω ng√¢n s√°ch?",
        "Ph√¢n lo·∫°i giao d·ªãch nh∆∞ th·∫ø n√†o?",
        "N√™n ƒë·∫ßu t∆∞ v√†o ƒë√¢u?"
    ]
    
    logger.info("\nTesting financial advice:")
    for query in test_queries:
        advice = ai.get_financial_advice(query)
        logger.info(f"Q: {query}")
        logger.info(f"A: {advice['answer'][:100]}...")
        logger.info(f"Confidence: {advice['confidence']}\n")

if __name__ == "__main__":
    main()