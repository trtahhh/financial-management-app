"""
MASSIVE Vietnamese Financial Dataset Generator
Generate 500K+ transactions with regional variations, comprehensive knowledge base
Target: ~50GB high-quality training data for maximum accuracy
"""

import json
import random
import itertools
from datetime import datetime, timedelta
import uuid
from typing import List, Dict, Set
import os

# MASSIVE Vietnamese transaction patterns with regional variations
TRANSACTION_PATTERNS = {
    "food_beverage": {
        "northern": [
            "Ä‚n phá»Ÿ {merchant} {amount}k", "CÃ  phÃª {merchant} {amount}k", "BÃ¡nh mÃ¬ {merchant} {amount}k",
            "ChÃ¨ {merchant} {amount}k", "BÃºn cháº£ {amount}k", "Nem nÆ°á»›ng {amount}k", 
            "CÆ¡m táº¥m {merchant} {amount}k", "TrÃ  Ä‘Ã¡ vá»‰a hÃ¨ {amount}k", "BÃ¡nh cuá»‘n {amount}k",
            "Phá»Ÿ gÃ  {merchant} {amount}k", "BÃºn riÃªu {amount}k", "BÃ¡nh giÃ² {amount}k"
        ],
        "southern": [
            "Há»§ tiáº¿u {merchant} {amount}k", "CÃ  phÃª sá»¯a Ä‘Ã¡ {merchant} {amount}k", "BÃ¡nh trÃ¡ng nÆ°á»›ng {amount}k",
            "CÆ¡m táº¥m sÆ°á»n {merchant} {amount}k", "ChÃ¨ Ä‘áº­u xanh {amount}k", "BÃ¡nh xÃ¨o {amount}k",
            "Gá»i cuá»‘n {merchant} {amount}k", "TrÃ  chanh {amount}k", "BÃ¡nh flan {amount}k",
            "BÃºn bÃ² Huáº¿ {merchant} {amount}k", "Cao láº§u {amount}k", "MÃ¬ Quáº£ng {amount}k"
        ],
        "central": [
            "BÃºn bÃ² Huáº¿ {merchant} {amount}k", "Cao láº§u Há»™i An {amount}k", "MÃ¬ Quáº£ng {amount}k",
            "BÃ¡nh khoÃ¡i {amount}k", "Nem lá»¥i {merchant} {amount}k", "ChÃ¨ Huáº¿ {amount}k"
        ],
        "chains": [
            "Highland Coffee {amount}k", "Starbucks {amount}k", "The Coffee House {amount}k",
            "KFC {amount}k", "Lotteria {amount}k", "McDonald's {amount}k", "Pizza Hut {amount}k",
            "Domino's Pizza {amount}k", "Gong Cha {amount}k", "Tocotoco {amount}k"
        ]
    },
    "transportation": {
        "ride_sharing": [
            "Grab xe Ã´m {distance}km {amount}k", "Be xe Ã´m {amount}k", "Gojek {amount}k",
            "Grab Car {distance}km {amount}k", "Be Car {amount}k", "Taxi {company} {amount}k",
            "Grab Bike tá»« {location1} Ä‘áº¿n {location2} {amount}k"
        ],
        "fuel": [
            "XÄƒng Shell {amount}k", "XÄƒng Petrolimex {amount}k", "XÄƒng Caltex {amount}k",
            "Äá»• xÄƒng A95 {amount}k", "XÄƒng E5 {amount}k", "Diesel {amount}k"
        ],
        "public_transport": [
            "VÃ© xe bus {route} {amount}k", "VÃ© tÃ u Ä‘iá»‡n ngáº§m {amount}k", "Xe buÃ½t BRT {amount}k",
            "VÃ© tÃ u há»a {from_city} - {to_city} {amount}k", "MÃ¡y bay {airline} {amount}k"
        ],
        "maintenance": [
            "Sá»­a xe mÃ¡y {amount}k", "Thay nhá»›t {brand} {amount}k", "Báº£o dÆ°á»¡ng xe {amount}k",
            "Rá»­a xe {amount}k", "BÆ¡m lá»‘p {amount}k", "ÄÄƒng kiá»ƒm xe {amount}k"
        ]
    },
    "shopping": {
        "fashion": [
            "Quáº§n Ã¡o {brand} {amount}k", "GiÃ y {brand} {amount}k", "TÃºi xÃ¡ch {amount}k",
            "Äá»“ lÃ³t {amount}k", "MÅ© nÃ³n {amount}k", "KÃ­nh mÃ¡t {brand} {amount}k",
            "Äá»“ng há»“ {brand} {amount}k", "Trang sá»©c {amount}k"
        ],
        "electronics": [
            "iPhone {model} {amount}k", "Samsung Galaxy {model} {amount}k", "Laptop {brand} {amount}k",
            "Tai nghe {brand} {amount}k", "Sáº¡c dá»± phÃ²ng {amount}k", "á»p lÆ°ng Ä‘iá»‡n thoáº¡i {amount}k",
            "Tivi {brand} {size}inch {amount}k", "MÃ¡y láº¡nh {brand} {amount}k"
        ],
        "ecommerce": [
            "Shopee {category} {amount}k", "Lazada {category} {amount}k", "Tiki sÃ¡ch {amount}k",
            "Sendo {category} {amount}k", "Fahasa sÃ¡ch {amount}k", "Being Ä‘á»“ gia dá»¥ng {amount}k"
        ],
        "supermarket": [
            "Co.opMart {items} {amount}k", "Big C {items} {amount}k", "Lotte Mart {amount}k",
            "Vinmart {items} {amount}k", "Aeon Mall {amount}k", "Saigon Co.op {amount}k"
        ]
    },
    "utilities": {
        "bills": [
            "Tiá»n Ä‘iá»‡n EVN thÃ¡ng {month} {amount}k", "Tiá»n nÆ°á»›c Sawaco {amount}k",
            "Internet FPT {speed}Mbps {amount}k", "Internet Viettel {amount}k",
            "Äiá»‡n thoáº¡i Viettel {amount}k", "Äiá»‡n thoáº¡i Vinaphone {amount}k",
            "Truyá»n hÃ¬nh cÃ¡p SCTV {amount}k", "Gas Petrolimex {amount}k"
        ],
        "housing": [
            "Tiá»n thuÃª nhÃ  Q{district} {amount}k", "Tiá»n nhÃ  chung cÆ° {amount}k",
            "PhÃ­ quáº£n lÃ½ chung cÆ° {amount}k", "Tiá»n gá»­i xe {amount}k",
            "Báº£o vá»‡ chung cÆ° {amount}k", "Vá»‡ sinh chung cÆ° {amount}k"
        ]
    },
    "healthcare": {
        "medical": [
            "KhÃ¡m bá»‡nh BV {hospital} {amount}k", "XÃ©t nghiá»‡m {test_type} {amount}k",
            "SiÃªu Ã¢m {amount}k", "Chá»¥p X-quang {amount}k", "MRI {amount}k",
            "Nha khoa {clinic} {amount}k", "Niá»ng rÄƒng {amount}k", "Cáº¯t amidan {amount}k"
        ],
        "pharmacy": [
            "Mua thuá»‘c {pharmacy} {amount}k", "Thuá»‘c cáº£m cÃºm {amount}k",
            "Vitamin {brand} {amount}k", "Thuá»‘c Ä‘au bá»¥ng {amount}k",
            "Kem bÃ´i da {amount}k", "NÆ°á»›c sÃºc miá»‡ng {amount}k"
        ],
        "insurance": [
            "BHYT thÃ¡ng {month} {amount}k", "Báº£o hiá»ƒm Prudential {amount}k",
            "BHXH Ä‘Ã³ng gÃ³p {amount}k", "Báº£o hiá»ƒm AIA {amount}k"
        ]
    },
    "entertainment": {
        "media": [
            "Netflix thÃ¡ng {month} {amount}k", "Spotify Premium {amount}k",
            "YouTube Premium {amount}k", "Apple Music {amount}k", "VTV Cab {amount}k"
        ],
        "gaming": [
            "Náº¡p LiÃªn QuÃ¢n {amount}k", "PUBG Mobile {amount}k", "FIFA Online {amount}k",
            "Game Steam {game} {amount}k", "Robux Roblox {amount}k"
        ],
        "activities": [
            "Xem phim CGV {movie} {amount}k", "Karaoke {venue} {amount}k",
            "Bowling {amount}k", "Billiards {amount}k", "Massage {amount}k",
            "Gym {club} {amount}k", "Yoga {amount}k", "BÆ¡i lá»™i {amount}k"
        ]
    },
    "education": {
        "formal": [
            "Há»c phÃ­ Ä‘áº¡i há»c {amount}k", "Há»c phÃ­ tiáº¿ng Anh {center} {amount}k",
            "KhÃ³a há»c láº­p trÃ¬nh {amount}k", "Há»c lÃ¡i xe {amount}k",
            "SÃ¡ch giÃ¡o khoa {amount}k", "Äá»“ dÃ¹ng há»c táº­p {amount}k"
        ],
        "online": [
            "Udemy khÃ³a {course} {amount}k", "Coursera {amount}k",
            "Edumall {amount}k", "Unica {amount}k", "Kyna.vn {amount}k"
        ]
    },
    "income": {
        "salary": [
            "LÆ°Æ¡ng thÃ¡ng {month} cÃ´ng ty {company}",
            "ThÆ°á»Ÿng cuá»‘i nÄƒm", "ThÆ°á»Ÿng dá»± Ã¡n {project}",
            "LÆ°Æ¡ng overtime thÃ¡ng {month}", "Phá»¥ cáº¥p Ä‘i láº¡i"
        ],
        "freelance": [
            "Freelance thiáº¿t káº¿ {project}", "Dá»‹ch thuáº­t tÃ i liá»‡u",
            "Viáº¿t content {topic}", "Chá»¥p áº£nh sá»± kiá»‡n {event}",
            "Dáº¡y kÃ¨m {subject}", "Láº­p trÃ¬nh {project}"
        ],
        "business": [
            "BÃ¡n hÃ ng online {platform}", "Kinh doanh cafe",
            "Cho thuÃª phÃ²ng trá»", "BÃ¡n bÃ¡nh handmade",
            "Dá»‹ch vá»¥ sá»­a chá»¯a", "Kinh doanh má»¹ pháº©m"
        ],
        "investment": [
            "LÃ£i tiá»n gá»­i ngÃ¢n hÃ ng", "Cá»• tá»©c {company}",
            "LÃ£i trÃ¡i phiáº¿u", "BÃ¡n cá»• phiáº¿u {stock}",
            "Thu nháº­p tá»« cho vay", "LÃ£i quá»¹ Ä‘áº§u tÆ°"
        ]
    }
}

# MASSIVE merchant/brand database
MERCHANTS = {
    "food_chains": [
        "Highland Coffee", "Starbucks", "The Coffee House", "PhÃºc Long", "Trung NguyÃªn",
        "KFC", "McDonald's", "Lotteria", "Jollibee", "Burger King", "Domino's", "Pizza Hut",
        "Gong Cha", "Tocotoco", "Ding Tea", "Royaltea", "Phindi", "Koi ThÃ©"
    ],
    "retail": [
        "Vinmart", "Co.opMart", "Big C", "Lotte Mart", "Aeon Mall", "Parkson",
        "FPT Shop", "Tháº¿ Giá»›i Di Äá»™ng", "CellphoneS", "Äiá»‡n MÃ¡y Xanh", "Nguyá»…n Kim",
        "Shopee", "Lazada", "Tiki", "Sendo", "Fahasa", "Being"
    ],
    "transport": [
        "Grab", "Be", "Gojek", "Mai Linh", "Vinasun", "G7", "Uber"
    ],
    "banks": [
        "Vietcombank", "BIDV", "Agribank", "Techcombank", "ACB", "MB Bank", "VP Bank"
    ],
    "hospitals": [
        "Chá»£ Ráº«y", "Báº¡ch Mai", "Viá»‡t Äá»©c", "Äáº¡i há»c Y", "Thu CÃºc", "Vinmec", "FV"
    ]
}

# Vietnamese locations for realistic transactions  
LOCATIONS = {
    "ho_chi_minh": [
        "Q1", "Q2", "Q3", "Q4", "Q5", "Q7", "BÃ¬nh Tháº¡nh", "TÃ¢n BÃ¬nh", "Thá»§ Äá»©c",
        "GÃ² Váº¥p", "PhÃº Nhuáº­n", "TÃ¢n PhÃº", "BÃ¬nh TÃ¢n", "Quáº­n 6", "Quáº­n 8"
    ],
    "hanoi": [
        "HoÃ n Kiáº¿m", "Ba ÄÃ¬nh", "Äá»‘ng Äa", "Hai BÃ  TrÆ°ng", "HoÃ ng Mai", "Long BiÃªn",
        "TÃ¢y Há»“", "Thanh XuÃ¢n", "Cáº§u Giáº¥y", "Nam Tá»« LiÃªm", "Báº¯c Tá»« LiÃªm"
    ],
    "danang": [
        "Háº£i ChÃ¢u", "Thanh KhÃª", "SÆ¡n TrÃ ", "NgÅ© HÃ nh SÆ¡n", "LiÃªn Chiá»ƒu", "Cáº©m Lá»‡"
    ]
}

# Amount ranges optimized for Vietnamese economy
AMOUNT_RANGES = {
    "food_beverage": (5, 2000),     # 5k - 2M (street food to luxury dining)
    "transportation": (5, 5000),    # 5k - 5M (bus to flight) 
    "shopping": (10, 100000),       # 10k - 100M (small items to luxury)
    "utilities": (50, 10000),       # 50k - 10M (monthly bills)
    "healthcare": (20, 50000),      # 20k - 50M (medicine to surgery)
    "entertainment": (10, 5000),    # 10k - 5M (small games to luxury entertainment)
    "education": (100, 200000),     # 100k - 200M (books to university)
    "income": (3000, 2000000)       # 3M - 2B (minimum wage to executive salary)
}

class MassiveDatasetGenerator:
    def __init__(self, target_size_gb: float = 45):
        self.target_size_gb = target_size_gb
        self.target_transactions = 500000  # 500K base transactions
        self.generated_descriptions: Set[str] = set()
        
    def generate_description_variants(self, base_pattern: str, **kwargs) -> List[str]:
        """Generate multiple variants of a transaction description"""
        variants = []
        
        # Basic substitution with safe formatting
        try:
            desc = base_pattern.format(**kwargs)
        except KeyError as e:
            # Use only available parameters 
            available_params = {k: v for k, v in kwargs.items() if f'{{{k}}}' in base_pattern}
            desc = base_pattern.format(**available_params) if available_params else base_pattern
        
        variants.append(desc)
        
        # Add time variants
        time_prefixes = ["", "SÃ¡ng ", "TrÆ°a ", "Chiá»u ", "Tá»‘i ", "HÃ´m nay ", "HÃ´m qua "]
        for prefix in time_prefixes:
            variants.append(f"{prefix}{desc.lower()}")
            
        # Add method variants
        payment_methods = ["", " - Momo", " - ZaloPay", " - ViettelPay", " - Tháº»", " - Tiá»n máº·t", " - Chuyá»ƒn khoáº£n"]
        for method in payment_methods:
            variants.append(f"{desc}{method}")
            
        return variants
    
    def generate_regional_transactions(self, region: str, num_transactions: int) -> List[Dict]:
        """Generate transactions specific to a region"""
        transactions = []
        
        for category, patterns_dict in TRANSACTION_PATTERNS.items():
            if category == "income":
                continue  # Handle income separately
                
            # Get regional patterns
            if region in patterns_dict:
                regional_patterns = patterns_dict[region]
            else:
                regional_patterns = patterns_dict.get("chains", list(patterns_dict.values())[0])
            
            category_count = num_transactions // len(TRANSACTION_PATTERNS)
            
            for _ in range(category_count):
                pattern = random.choice(regional_patterns)
                
                # Generate parameters
                min_amt, max_amt = AMOUNT_RANGES.get(category, (10, 1000))
                amount = random.randint(min_amt, max_amt)
                
                # Comprehensive parameter set
                kwargs = {
                    'amount': amount,
                    'merchant': random.choice(MERCHANTS.get('food_chains', ['Highland'])),
                    'distance': random.randint(1, 50),
                    'location1': random.choice(LOCATIONS.get('ho_chi_minh', ['Q1'])),
                    'location2': random.choice(LOCATIONS.get('ho_chi_minh', ['Q2'])),
                    'month': random.randint(1, 12),
                    'district': random.randint(1, 12),
                    'company': random.choice(['Shell', 'Petrolimex', 'Caltex']),
                    'brand': random.choice(['Samsung', 'Apple', 'Nike', 'Adidas']),
                    'route': f"Tuyáº¿n {random.randint(1, 150)}",
                    'from_city': random.choice(['TP.HCM', 'HÃ  Ná»™i', 'ÄÃ  Náºµng']),
                    'to_city': random.choice(['Nha Trang', 'Há»™i An', 'VÅ©ng TÃ u']),
                    'airline': random.choice(['Vietnam Airlines', 'Jetstar', 'VietJet']),
                    'category': random.choice(['Ä‘iá»‡n tá»­', 'thá»i trang', 'gia dá»¥ng']),
                    'items': random.choice(['thá»±c pháº©m', 'Ä‘á»“ gia dá»¥ng', 'rau cá»§']),
                    'speed': random.choice([30, 50, 100, 200]),
                    'hospital': random.choice(MERCHANTS.get('hospitals', ['BV Chá»£ Ráº«y'])),
                    'test_type': random.choice(['mÃ¡u', 'nÆ°á»›c tiá»ƒu', 'tá»•ng quÃ¡t']),
                    'pharmacy': random.choice(['Pharmacity', 'Long ChÃ¢u', 'An Khang']),
                    'game': random.choice(['CS:GO', 'PUBG', 'FIFA', 'LOL']),
                    'movie': random.choice(['Avatar', 'Spider-Man', 'Fast & Furious']),
                    'venue': random.choice(['Arirang', 'Newway', 'Family']),
                    'club': random.choice(['California', 'Elite', 'Gym Plus']),
                    'center': random.choice(['ILA', 'Wall Street', 'Apollo']),
                    'course': random.choice(['Python', 'React', 'AI', 'Marketing']),
                    'model': random.choice(['S24', 'iPhone 15', 'Galaxy A55']),
                    'size': random.choice([43, 50, 55, 65]),
                    'clinic': random.choice(['Nha Khoa Paris', 'RÄƒng HÃ m Máº·t'])
                }
                
                # Generate variants
                variants = self.generate_description_variants(pattern, **kwargs)
                
                for variant in variants:
                    if variant not in self.generated_descriptions:
                        self.generated_descriptions.add(variant)
                        
                        transactions.append({
                            "id": str(uuid.uuid4()),
                            "description": variant,
                            "category": category,
                            "amount": amount * 1000,  # Convert to VND
                            "type": "EXPENSE",
                            "confidence": 1.0,
                            "region": region,
                            "timestamp": self.random_timestamp(),
                            "metadata": {
                                "pattern_source": pattern,
                                "generation_method": "regional_variant"
                            }
                        })
        
        return transactions
    
    def random_timestamp(self) -> str:
        """Generate random timestamp within last 2 years"""
        start_date = datetime.now() - timedelta(days=730)
        random_days = random.randint(0, 730)
        random_date = start_date + timedelta(days=random_days)
        return random_date.isoformat()
    
    def generate_income_transactions(self, num_transactions: int) -> List[Dict]:
        """Generate comprehensive income transactions"""
        transactions = []
        
        income_patterns = TRANSACTION_PATTERNS["income"]
        
        for _ in range(num_transactions):
            category_type = random.choice(list(income_patterns.keys()))
            pattern = random.choice(income_patterns[category_type])
            
            # Income amounts (in thousands VND)
            min_amt, max_amt = AMOUNT_RANGES["income"]
            amount = random.randint(min_amt, max_amt)
            
            kwargs = {
                'month': random.randint(1, 12),
                'company': f"CÃ´ng ty {random.choice(['ABC', 'XYZ', 'Tech', 'Solutions', 'Digital'])}",
                'project': f"Dá»± Ã¡n {random.choice(['Web', 'Mobile', 'AI', 'Blockchain'])}",
                'platform': random.choice(['Shopee', 'Lazada', 'Facebook', 'Zalo']),
                'subject': random.choice(['ToÃ¡n', 'Anh vÄƒn', 'Láº­p trÃ¬nh', 'Guitar']),
                'event': random.choice(['CÆ°á»›i há»i', 'Sinh nháº­t', 'CÃ´ng ty', 'Há»™i nghá»‹']),
                'stock': f"{random.choice(['VIC', 'VCB', 'GAS', 'MSN', 'HPG'])}",
                'topic': random.choice(['Tech', 'Du lá»‹ch', 'áº¨m thá»±c', 'Thá»i trang'])
            }
            
            description = pattern.format(**kwargs)
            
            transactions.append({
                "id": str(uuid.uuid4()),
                "description": description,
                "category": "income",
                "amount": amount * 1000,
                "type": "INCOME",
                "confidence": 1.0,
                "region": "national",
                "timestamp": self.random_timestamp(),
                "metadata": {
                    "income_type": category_type,
                    "generation_method": "income_comprehensive"
                }
            })
        
        return transactions
    
    def generate_massive_dataset(self) -> List[Dict]:
        """Generate massive 500K+ transaction dataset"""
        print(f"ğŸš€ Generating MASSIVE dataset targeting {self.target_size_gb}GB...")
        
        all_transactions = []
        
        # Generate regional transactions
        regions = ["northern", "southern", "central", "chains"]
        transactions_per_region = self.target_transactions // len(regions)
        
        for region in regions:
            print(f"ğŸ¢ Generating {transactions_per_region:,} transactions for {region} region...")
            regional_tx = self.generate_regional_transactions(region, transactions_per_region)
            all_transactions.extend(regional_tx)
            print(f"âœ… Generated {len(regional_tx):,} {region} transactions")
        
        # Generate income transactions (20% of total)
        income_count = len(all_transactions) // 4
        print(f"ğŸ’° Generating {income_count:,} income transactions...")
        income_tx = self.generate_income_transactions(income_count)
        all_transactions.extend(income_tx)
        
        print(f"ğŸ“Š Total generated: {len(all_transactions):,} transactions")
        print(f"ğŸ“ Unique descriptions: {len(self.generated_descriptions):,}")
        
        return all_transactions

def generate_comprehensive_financial_knowledge() -> Dict:
    """Generate comprehensive financial knowledge base"""
    
    return {
        "transaction_keywords": {
            "food_vietnamese": [
                "phá»Ÿ", "bÃºn", "bÃ¡nh mÃ¬", "cÆ¡m táº¥m", "há»§ tiáº¿u", "bÃ¡nh xÃ¨o", 
                "gá»i cuá»‘n", "nem", "chÃ¨", "bÃ¡nh flan", "trÃ  sá»¯a", "cÃ  phÃª"
            ],
            "shopping_vietnamese": [
                "mua", "shopping", "order", "Ä‘áº·t hÃ ng", "thanh toÃ¡n", "pay",
                "quáº§n Ã¡o", "giÃ y dÃ©p", "tÃºi xÃ¡ch", "má»¹ pháº©m", "Ä‘iá»‡n thoáº¡i"
            ],
            "transport_vietnamese": [
                "grab", "be", "taxi", "xe Ã´m", "bus", "xe buÃ½t", "xÄƒng", 
                "Ä‘á»• xÄƒng", "sá»­a xe", "rá»­a xe", "vÃ© tÃ u", "mÃ¡y bay"
            ],
            "bills_vietnamese": [
                "tiá»n Ä‘iá»‡n", "tiá»n nÆ°á»›c", "internet", "Ä‘iá»‡n thoáº¡i", "thuÃª nhÃ ",
                "phÃ­", "cÆ°á»›c", "hÃ³a Ä‘Æ¡n", "bill", "EVN", "FPT", "Viettel"
            ]
        },
        "amount_patterns": {
            "currency_units": ["k", "nghÃ¬n", "triá»‡u", "tr", "Ä‘", "vnd", "dong", "vnÄ‘"],
            "number_words": [
                "má»™t", "hai", "ba", "bá»‘n", "nÄƒm", "sÃ¡u", "báº£y", "tÃ¡m", "chÃ­n", "mÆ°á»i",
                "mÆ°á»i má»™t", "mÆ°á»i hai", "hai mÆ°á»i", "ba mÆ°á»i", "nÄƒm mÆ°á»i", "trÄƒm"
            ],
            "amount_indicators": ["giÃ¡", "tá»•ng", "total", "cost", "chi phÃ­", "thanh toÃ¡n"]
        },
        "merchant_categories": {
            "food_merchants": MERCHANTS["food_chains"],
            "retail_merchants": MERCHANTS["retail"], 
            "transport_merchants": MERCHANTS["transport"],
            "bank_merchants": MERCHANTS["banks"]
        },
        "location_patterns": {
            "ho_chi_minh": LOCATIONS["ho_chi_minh"],
            "hanoi": LOCATIONS["hanoi"], 
            "danang": LOCATIONS["danang"]
        }
    }

def generate_comprehensive_advice_database() -> List[Dict]:
    """Generate comprehensive financial advice database"""
    
    scenarios = [
        {
            "scenario": "tiáº¿t kiá»‡m cho ngÆ°á»i má»›i báº¯t Ä‘áº§u",
            "tags": ["tiáº¿t_kiá»‡m", "ngÆ°á»i_má»›i", "cÆ¡_báº£n"],
            "advice": "Báº¯t Ä‘áº§u vá»›i viá»‡c theo dÃµi chi tiÃªu hÃ ng ngÃ y vÃ  Ã¡p dá»¥ng quy táº¯c 50-30-20: 50% nhu cáº§u thiáº¿t yáº¿u, 30% mong muá»‘n, 20% tiáº¿t kiá»‡m.",
            "detailed_tips": [
                "Ghi chÃ©p táº¥t cáº£ chi tiÃªu trong 30 ngÃ y Ä‘á»ƒ hiá»ƒu rÃµ pattern",
                "Sá»­ dá»¥ng app quáº£n lÃ½ tÃ i chÃ­nh Ä‘á»ƒ theo dÃµi tá»± Ä‘á»™ng",
                "Äáº·t má»¥c tiÃªu tiáº¿t kiá»‡m cá»¥ thá»ƒ: VD 2 triá»‡u/thÃ¡ng", 
                "Tá»± Ä‘á»™ng chuyá»ƒn tiá»n tiáº¿t kiá»‡m ngay khi nháº­n lÆ°Æ¡ng",
                "Cáº¯t giáº£m chi tiÃªu khÃ´ng cáº§n thiáº¿t nhÆ° cafe, Ä‘á»“ Äƒn nhanh"
            ],
            "examples": [
                "Thay vÃ¬ mua cafe 50k/ngÃ y, pha cafe táº¡i nhÃ  tiáº¿t kiá»‡m 1.2tr/thÃ¡ng",
                "Náº¥u Äƒn táº¡i nhÃ  thay vÃ¬ order Ä‘á»“ Äƒn tiáº¿t kiá»‡m 3-5tr/thÃ¡ng"
            ]
        },
        {
            "scenario": "quáº£n lÃ½ ná»£ tháº» tÃ­n dá»¥ng", 
            "tags": ["ná»£", "tháº»_tÃ­n_dá»¥ng", "quáº£n_lÃ½_ná»£"],
            "advice": "Æ¯u tiÃªn tráº£ ná»£ tháº» tÃ­n dá»¥ng cÃ³ lÃ£i suáº¥t cao nháº¥t trÆ°á»›c, Ä‘á»“ng thá»i duy trÃ¬ thanh toÃ¡n tá»‘i thiá»ƒu cho cÃ¡c tháº» khÃ¡c.",
            "detailed_tips": [
                "Liá»‡t kÃª táº¥t cáº£ tháº» tÃ­n dá»¥ng vá»›i sá»‘ dÆ° vÃ  lÃ£i suáº¥t",
                "Ãp dá»¥ng phÆ°Æ¡ng phÃ¡p 'debt avalanche': tráº£ ná»£ lÃ£i suáº¥t cao trÆ°á»›c",
                "ÄÃ m phÃ¡n vá»›i ngÃ¢n hÃ ng Ä‘á»ƒ giáº£m lÃ£i suáº¥t hoáº·c gia háº¡n",
                "Cáº¯t bá» cÃ¡c tháº» khÃ´ng cáº§n thiáº¿t Ä‘á»ƒ trÃ¡nh cÃ¡m dá»— chi tiÃªu",
                "Chuyá»ƒn ná»£ sang tháº» cÃ³ lÃ£i suáº¥t tháº¥p hÆ¡n náº¿u cÃ³ thá»ƒ"
            ],
            "examples": [
                "Tháº» A: 5tr - 25%/nÄƒm, Tháº» B: 3tr - 20%/nÄƒm â†’ Tráº£ tháº» A trÆ°á»›c",
                "Chuyá»ƒn ná»£ tá»« tháº» 25%/nÄƒm sang tháº» 15%/nÄƒm tiáº¿t kiá»‡m 500k/nÄƒm"
            ]
        }
        # Add more comprehensive scenarios...
    ]
    
    return scenarios

if __name__ == "__main__":
    generator = MassiveDatasetGenerator(target_size_gb=45)
    
    print("ğŸ”¥ MASSIVE VIETNAMESE FINANCIAL DATASET GENERATOR")
    print("=" * 60)
    print(f"Target: {generator.target_size_gb}GB of high-quality training data")
    print(f"Expected transactions: {generator.target_transactions:,}+")
    print()
    
    # Generate massive transaction dataset
    transactions = generator.generate_massive_dataset()
    
    # Save in chunks for better memory management
    chunk_size = 50000
    chunks = [transactions[i:i + chunk_size] for i in range(0, len(transactions), chunk_size)]
    
    print(f"ğŸ’¾ Saving {len(chunks)} chunks of {chunk_size:,} transactions each...")
    
    for i, chunk in enumerate(chunks):
        filename = f"transactions_massive_chunk_{i+1:03d}.json"
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(chunk, f, ensure_ascii=False, indent=1)
        
        file_size = os.path.getsize(filename) / (1024 * 1024)  # MB
        print(f"âœ… Saved {filename}: {len(chunk):,} transactions ({file_size:.1f}MB)")
    
    # Generate comprehensive knowledge base
    print("\nğŸ“š Generating comprehensive financial knowledge...")
    knowledge = generate_comprehensive_financial_knowledge()
    
    with open("financial_knowledge_comprehensive.json", "w", encoding="utf-8") as f:
        json.dump(knowledge, f, ensure_ascii=False, indent=2)
    
    # Generate comprehensive advice database
    print("ğŸ’¡ Generating comprehensive advice database...")
    advice_db = generate_comprehensive_advice_database()
    
    with open("advice_database_comprehensive.json", "w", encoding="utf-8") as f:
        json.dump(advice_db, f, ensure_ascii=False, indent=2)
    
    # Calculate total dataset size
    total_size = sum(os.path.getsize(f"transactions_massive_chunk_{i+1:03d}.json") 
                    for i in range(len(chunks)))
    total_size_gb = total_size / (1024 ** 3)
    
    print("\nğŸ¯ MASSIVE DATASET GENERATION COMPLETE!")
    print("=" * 60)
    print(f"ğŸ“Š Total transactions: {len(transactions):,}")
    print(f"ğŸ“ Unique descriptions: {len(generator.generated_descriptions):,}")
    print(f"ğŸ’¾ Dataset size: {total_size_gb:.2f}GB")
    print(f"ğŸ“ Files generated: {len(chunks)} transaction chunks + knowledge bases")
    print(f"ğŸ† Ready for industrial-grade PhoBERT training!")