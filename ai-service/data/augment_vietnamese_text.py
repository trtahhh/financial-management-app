"""
Data Augmentation for Vietnamese Financial Text
Advanced techniques to expand dataset diversity and quality
"""

import json
import random
import re
from typing import List, Dict, Set
from dataclasses import dataclass
import itertools

@dataclass
class AugmentationRule:
    """Rule for text augmentation"""
    name: str
    pattern: str
    replacements: List[str]
    probability: float = 0.3

class VietnameseTextAugmenter:
    """Advanced Vietnamese text augmentation for financial transactions"""
    
    def __init__(self):
        self.augmentation_rules = self._load_augmentation_rules()
        self.synonym_dict = self._load_vietnamese_synonyms()
        self.slang_dict = self._load_vietnamese_slang()
        
    def _load_augmentation_rules(self) -> List[AugmentationRule]:
        """Load augmentation rules for Vietnamese financial text"""
        return [
            AugmentationRule(
                "payment_methods",
                r"\b(mua|thanh toÃ¡n|tráº£)\b",
                ["mua", "thanh toÃ¡n", "tráº£", "chi", "Ä‘Ã³ng", "ná»™p"],
                0.4
            ),
            AugmentationRule(
                "time_expressions", 
                r"\b(hÃ´m nay|hÃ´m qua|sÃ¡ng|trÆ°a|chiá»u|tá»‘i)\b",
                ["hÃ´m nay", "hÃ´m qua", "sÃ¡ng nay", "trÆ°a nay", "chiá»u nay", "tá»‘i nay", ""],
                0.3
            ),
            AugmentationRule(
                "location_modifiers",
                r"\bá»Ÿ\s+",
                ["á»Ÿ ", "táº¡i ", "bÃªn ", ""],
                0.2
            ),
            AugmentationRule(
                "amount_formats",
                r"(\d+)k\b",
                lambda m: random.choice([f"{m.group(1)}k", f"{m.group(1)} nghÃ¬n", f"{m.group(1)}.000Ä‘"]),
                0.4
            )
        ]
    
    def _load_vietnamese_synonyms(self) -> Dict[str, List[str]]:
        """Load Vietnamese synonym dictionary for financial terms"""
        return {
            "mua": ["mua", "sáº¯m", "táº­u", "order", "Ä‘áº·t"],
            "Äƒn": ["Äƒn", "dÃ¹ng bá»¯a", "Äƒn uá»‘ng", "nháº­u", "buffet"],
            "uá»‘ng": ["uá»‘ng", "nhÃ¢m nhi", "thÆ°á»Ÿng thá»©c", "order"],
            "Ä‘i": ["Ä‘i", "di chuyá»ƒn", "bay", "lÃ¡i xe", "xuá»‘ng"],
            "cÃ  phÃª": ["cÃ  phÃª", "coffee", "cafe", "cf", "caphe"],
            "tiá»n": ["tiá»n", "cash", "money", "Ä‘á»“ng", "báº¡c"],
            "vá»›i": ["vá»›i", "cÃ¹ng", "vÃ ", "&"],
            "cho": ["cho", "Ä‘á»ƒ", "dÃ nh cho", "phá»¥c vá»¥"],
            "cá»§a": ["cá»§a", "thuá»™c", "do"],
            "táº¡i": ["táº¡i", "á»Ÿ", "bÃªn", "trong"],
            "tá»«": ["tá»«", "xuáº¥t phÃ¡t tá»«", "báº¯t Ä‘áº§u tá»«"],
            "Ä‘áº¿n": ["Ä‘áº¿n", "tá»›i", "vá»", "Ä‘i tá»›i"]
        }
    
    def _load_vietnamese_slang(self) -> Dict[str, List[str]]:
        """Load Vietnamese slang and informal expressions"""
        return {
            "mua": ["táº­u", "sáº¯m", "mÃºc", "chá»‘t Ä‘Æ¡n"],
            "Äƒn": ["xÆ¡i", "hÃºp", "cÃ y", "quáº©y"],
            "uá»‘ng": ["hÃºp", "nhÃ¢m nhi", "poppy"], 
            "Ä‘i": ["Ä‘i lÄƒn", "phÄƒng", "bay"],
            "tiá»n": ["xu", "Ä‘á»“ng", "tiá»n báº¡c", "money"],
            "Ä‘áº¯t": ["chÃ¡t", "chÃ¡y tÃºi", "máº¯c", "giÃ¡ cáº¯t cá»•"],
            "ráº»": ["bÃ¨o", "há»i", "giÃ¡ bÃ¹i"],
            "ngon": ["ngon tuyá»‡t", "xuáº¥t sáº¯c", "tuyá»‡t vá»i", "5 sao"],
            "xáº¥u": ["dá»Ÿ", "tá»‡", "khÃ´ng á»•n", "fail"]
        }
    
    def augment_synonym_replacement(self, text: str) -> List[str]:
        """Replace words with Vietnamese synonyms"""
        variants = []
        words = text.split()
        
        # Generate multiple combinations
        for _ in range(3):  # Generate 3 variants
            new_words = []
            for word in words:
                word_clean = re.sub(r'[^\w]', '', word.lower())
                if word_clean in self.synonym_dict and random.random() < 0.3:
                    replacement = random.choice(self.synonym_dict[word_clean])
                    new_words.append(replacement)
                else:
                    new_words.append(word)
            
            variant = ' '.join(new_words)
            if variant != text:
                variants.append(variant)
        
        return variants
    
    def augment_slang_injection(self, text: str) -> List[str]:
        """Inject Vietnamese slang and informal expressions"""
        variants = []
        
        for base_word, slang_options in self.slang_dict.items():
            if base_word in text.lower():
                for slang in slang_options:
                    if random.random() < 0.2:  # 20% chance to use slang
                        variant = text.replace(base_word, slang)
                        variants.append(variant)
        
        return variants
    
    def augment_regional_variations(self, text: str) -> List[str]:
        """Add regional Vietnamese variations"""
        variants = []
        
        regional_replacements = {
            "northern": {
                "cÃ  phÃª": "cafÃ©", "bÃ¡nh mÃ¬": "bÃ¡nh má»³", 
                "xe Ã´m": "xe Ã´m", "gá»i": "gá»i Ä‘iá»‡n"
            },
            "southern": {
                "cÃ  phÃª": "cafe", "bÃ¡nh mÃ¬": "bÃ¡nh mÃ¬", 
                "xe Ã´m": "xe om", "gá»i": "call"
            },
            "central": {
                "cÃ  phÃª": "cÃ  phÃª", "bÃ¡nh mÃ¬": "bÃ¡nh mÃ¬ Há»™i An"
            }
        }
        
        for region, replacements in regional_replacements.items():
            variant_text = text
            for original, replacement in replacements.items():
                if original in variant_text.lower():
                    variant_text = variant_text.replace(original, replacement)
            
            if variant_text != text:
                variants.append(variant_text)
        
        return variants
    
    def augment_typos_and_misspellings(self, text: str) -> List[str]:
        """Add realistic Vietnamese typing errors"""
        variants = []
        
        # Common Vietnamese typing mistakes
        typo_mappings = {
            'Äƒ': ['a', 'Ã¢'], 'Ã¢': ['a', 'Äƒ'], 'Ãª': ['e'], 'Ã´': ['o', 'Æ¡'],
            'Æ¡': ['o', 'Ã´'], 'Æ°': ['u'], 'Ä‘': ['d'], 'q': ['qu'], 'gi': ['g'],
            'ph': ['f'], 'th': ['t'], 'kh': ['k'], 'gh': ['g'], 'ng': ['n']
        }
        
        # Generate typo variants (low probability)
        if random.random() < 0.1:  # 10% chance for typos
            words = text.split()
            typo_text = []
            
            for word in words:
                if random.random() < 0.2:  # 20% chance to modify a word
                    for original, replacements in typo_mappings.items():
                        if original in word:
                            replacement = random.choice(replacements)
                            word = word.replace(original, replacement, 1)
                            break
                typo_text.append(word)
            
            variant = ' '.join(typo_text)
            if variant != text:
                variants.append(variant)
        
        return variants
    
    def augment_formatting_variations(self, text: str) -> List[str]:
        """Add formatting and punctuation variations"""
        variants = []
        
        # Case variations
        variants.extend([
            text.lower(),
            text.upper(), 
            text.title(),
            text.capitalize()
        ])
        
        # Punctuation variations
        punctuation_variants = [
            text + ".",
            text + "!",
            text.replace(" ", "_"),
            text.replace(" ", "-"),
            f"ðŸ’° {text}",
            f"{text} ðŸ›’",
            f"âœ… {text}"
        ]
        
        variants.extend(punctuation_variants)
        
        return [v for v in variants if v != text]
    
    def augment_transaction(self, transaction: Dict) -> List[Dict]:
        """Augment a single transaction with multiple techniques"""
        original_desc = transaction['description']
        augmented_transactions = []
        
        # Apply all augmentation techniques
        all_variants = []
        all_variants.extend(self.augment_synonym_replacement(original_desc))
        all_variants.extend(self.augment_slang_injection(original_desc))
        all_variants.extend(self.augment_regional_variations(original_desc))
        all_variants.extend(self.augment_typos_and_misspellings(original_desc))
        all_variants.extend(self.augment_formatting_variations(original_desc))
        
        # Remove duplicates and original
        unique_variants = list(set(all_variants))
        unique_variants = [v for v in unique_variants if v != original_desc and len(v.strip()) > 0]
        
        # Create augmented transactions
        for variant in unique_variants[:5]:  # Limit to 5 variants per transaction
            augmented_tx = transaction.copy()
            augmented_tx['description'] = variant
            augmented_tx['metadata'] = transaction.get('metadata', {}).copy()
            augmented_tx['metadata']['augmentation_method'] = 'vietnamese_advanced'
            augmented_tx['metadata']['original_description'] = original_desc
            augmented_transactions.append(augmented_tx)
        
        return augmented_transactions

def augment_massive_dataset(input_files: List[str], output_prefix: str = "augmented"):
    """Augment massive dataset with Vietnamese text variations"""
    
    augmenter = VietnameseTextAugmenter()
    
    for file_path in input_files:
        print(f"ðŸ”„ Augmenting {file_path}...")
        
        # Load original data
        with open(file_path, 'r', encoding='utf-8') as f:
            original_transactions = json.load(f)
        
        # Augment transactions
        augmented_data = []
        for i, transaction in enumerate(original_transactions):
            if i % 1000 == 0:
                print(f"   Processed {i:,} transactions...")
            
            # Add original transaction
            augmented_data.append(transaction)
            
            # Add augmented variants (with sampling to control size)
            if random.random() < 0.3:  # 30% chance to augment
                variants = augmenter.augment_transaction(transaction)
                augmented_data.extend(variants)
        
        # Save augmented data
        output_file = f"{output_prefix}_{file_path}"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(augmented_data, f, ensure_ascii=False, indent=1)
        
        expansion_ratio = len(augmented_data) / len(original_transactions)
        print(f"âœ… {output_file}: {len(augmented_data):,} transactions ({expansion_ratio:.1f}x expansion)")

if __name__ == "__main__":
    print("ðŸš€ VIETNAMESE TEXT AUGMENTATION SYSTEM")
    print("=" * 50)
    
    # Example usage - will be applied after massive dataset generation completes
    sample_text = "Mua cÃ  phÃ© Highland Coffee 45k"
    augmenter = VietnameseTextAugmenter()
    
    print(f"Original: {sample_text}")
    print("\nðŸ“ Augmentation Examples:")
    
    variants = []
    variants.extend(augmenter.augment_synonym_replacement(sample_text))
    variants.extend(augmenter.augment_slang_injection(sample_text))
    variants.extend(augmenter.augment_regional_variations(sample_text))
    
    for i, variant in enumerate(variants[:10], 1):
        print(f"{i:2d}. {variant}")
    
    print(f"\nðŸŽ¯ Ready to augment massive dataset when generation completes!")
    print("   This will expand 500K â†’ 1M+ transactions with Vietnamese variations")