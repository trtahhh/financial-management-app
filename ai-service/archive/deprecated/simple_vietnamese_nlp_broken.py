#!/usr/bin/env python3
"""
Simplified Vietnamese NLP Pipeline
Using underthesea and pyvi for Vietnamese transaction analysis without transformers compatibility issues
"""

import os
import json
import logging
from typing import List, Dict, Any, Optional, Tuple
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd
from datetime import datetime
import pickle
import glob
import re

# Vietnamese NLP tools
try:
 import underthesea
 UNDERTHESEA_AVAILABLE = True
except ImportError:
 UNDERTHESEA_AVAILABLE = False

try:
 from pyvi import ViTokenizer
 PYVI_AVAILABLE = True
except ImportError:
 PYVI_AVAILABLE = False

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SimpleVietnameseNLPProcessor:
    """
    Simplified Vietnamese NLP processor for financial transaction analysis
    Uses underthesea and pyvi instead of PhoBERT to avoid compatibility issues
    """

    def __init__(self, cache_dir: str = "./models"):
        """
        Initialize Vietnamese NLP processor

        Args:
        cache_dir: Directory to cache models
        """
        self.cache_dir = cache_dir

        # Create cache directory
        os.makedirs(cache_dir, exist_ok=True)

        logger.info(f" Initializing Simple Vietnamese NLP processor...")
        logger.info(f"üì¶ Underthesea available: {UNDERTHESEA_AVAILABLE}")
            logger.info(f"üì¶ PyVi available: {PYVI_AVAILABLE}")

        # Vietnamese financial categories with enhanced keywords and patterns
        self.vietnamese_categories = {
                'food': {
        'keywords': [
        # Main food keywords
                        'ƒÉn', 'u·ªëng', 'ph·ªü', 'c∆°m', 'b√°nh', 'ch√®', 'cafe', 'qu√°n', 'nh√† h√†ng', 'buffet',
                        'ƒë·ªì ƒÉn', 'th·ª©c ƒÉn', 'b√∫n', 'mi·∫øn', 'h·ªß ti·∫øu', 'ch√°o', 'x√¥i', 'nem', 'g·ªèi',
        # Chain restaurants
                        'kfc', 'mcdonald', 'lotteria', 'jollibee', 'pizza hut', 'domino',
        # Vietnamese food terms
                        't√°i', 'n·∫°m', 'g·∫ßu', 's∆∞·ªùn', 'ch·∫£', 'th·ªãt n∆∞·ªõng', 'b√°nh x√®o', 'b√°nh cu·ªën',
        # Drinks
                        'tr√†', 'c√† ph√™', 'n∆∞·ªõc', 'bia', 'r∆∞·ª£u', 'sinh t·ªë', 'n∆∞·ªõc ng·ªçt'
                ],
        'patterns': [
                r'qu√°n\s+\w+', r'ph·ªü\s+\w+', r'c∆°m\s+\w+', r'b√°nh\s+\w+',
                r'\w+\s*k(?:\s|$)', r'combo\s+\w+', r'set\s+\w+'
        ]
        },
        'transport': {
        'keywords': [
        # Transportation
                'xe', 'taxi', 'grab', 'bus', 'xe bu√Ωt', 'xe √¥m', 'xƒÉng', 'd·∫ßu', 'v√©', 't√†u',
                'm√°y bay', 'di chuy·ªÉn', 'ƒëi l·∫°i', 'be', 'gojek', 'uber',
        # Fuel and maintenance
                'petrolimex', 'shell', 'caltex', 'pvoil', 'xƒÉng ron', 'a92', 'a95', 'd·∫ßu diesel',
        # Airlines and transport companies
                'vietnam airlines', 'vietjet', 'bamboo airways', 'mai linh', 'vinasun', 'ti√™n sa',
        # Locations and routes
                't·ª´', 'ƒë·∫øn', 'ƒëi', 'v·ªÅ', 'tuy·∫øn', 'chuy·∫øn'
        ],
        'patterns': [
            r'grab\s+\w+', r't·ª´\s+\w+\s+ƒë·∫øn\s+\w+', r'tuy·∫øn\s+\w+',
            r'xƒÉng\s+\w+', r'v√©\s+\w+', r'\w+k\s*(?:t·ª´|ƒë·∫øn)'
        ]
        },
        'shopping': {
        'keywords': [
        # Shopping general
                'mua', 's·∫Øm', 'si√™u th·ªã', 'ch·ª£', 'shop', 'store', 'c·ª≠a h√†ng', 'trung t√¢m th∆∞∆°ng m·∫°i',
        # Clothing and accessories
                '√°o', 'qu·∫ßn', 'gi√†y', 'd√©p', 't√∫i', 'v√≠', 'ƒë·ªìng h·ªì', 'k√≠nh', 'm≈©', 'th·∫Øt l∆∞ng',
        # Supermarkets and stores
                'vinmart', 'coopmart', 'lotte mart', 'big c', 'metro', 'aeon', 'saigon coop',
                'circle k', 'gs25', 'ministop', 'family mart', 'b\'s mart',
        # Electronics
                'ƒëi·ªán tho·∫°i', 'laptop', 'iphone', 'samsung', 'oppo', 'vivo', 'xiaomi',
        # General items
                'ƒë·ªì d√πng', 's·∫£n ph·∫©m', 'h√†ng h√≥a', 'm·ªπ ph·∫©m', 'n∆∞·ªõc hoa'
        ],
        'patterns': [
            r'mua\s+\w+', r'si√™u th·ªã\s+\w+', r'shop\s+\w+',
            r'vinmart\+?', r'circle\s*k', r'gs\d+'
        ]
        },
        'entertainment': {
        'keywords': [
        # Entertainment venues
                'phim', 'r·∫°p', 'cinema', 'karaoke', 'game', 'vui ch∆°i', 'gi·∫£i tr√≠', 'th·ªÉ thao',
                'gym', 'spa', 'massage', 'bar', 'club', 'pub', 'disco',
        # Cinemas
                'cgv', 'lotte cinema', 'galaxy', 'beta', 'cinestar', 'bhd',
        # Sports and fitness
                'b√≥ng ƒë√°', 'tennis', 'c·∫ßu l√¥ng', 'b∆°i l·ªôi', 'yoga', 'aerobic', 'zumba',
        # Entertainment activities
                'bowling', 'billiards', 'bi-a', 'game center', 'timezone', 'quantum'
        ],
        'patterns': [
            r'xem\s+phim', r'cgv\s+\w+', r'karaoke\s+\w+',
            r'gym\s+\w+', r'spa\s+\w+', r'game\s+\w+'
        ]
        },
        'utilities': {
        'keywords': [
        # Basic utilities
                'ƒëi·ªán', 'n∆∞·ªõc', 'internet', 'ƒëi·ªán tho·∫°i', 'gas', 'ƒëi·ªán l·ª±c', 'n∆∞·ªõc s·∫°ch',
        # Utility companies
                'evn', 'vnpt', 'fpt', 'viettel', 'mobifone', 'vinaphone', 'vietnamobile',
                'sawaco', 'hwaco', 'capewaco', 'petrovietnam gas',
        # Services
                'c√°p quang', 'wifi', 'adsl', 'fiber', '3g', '4g', '5g', 'truy·ªÅn h√¨nh',
        # Bills
                'h√≥a ƒë∆°n', 'ti·ªÅn', 'ph√≠', 'c∆∞·ªõc'
        ],
        'patterns': [
            r'ti·ªÅn\s+ƒëi·ªán', r'ti·ªÅn\s+n∆∞·ªõc', r'internet\s+\w+',
            r'evn\s*\w*', r'fpt\s*\w*', r'viettel\s*\w*'
        ]
        },
        'healthcare': {
        'keywords': [
        # Medical facilities
                'b·ªánh vi·ªán', 'ph√≤ng kh√°m', 'kh√°m', 'ch·ªØa', 'ƒëi·ªÅu tr·ªã', 'thu·ªëc', 'y t·∫ø',
                'b√°c sƒ©', 'th·∫ßy thu·ªëc', 'nha khoa', 'rƒÉng', 'm·∫Øt', 'tim', 'gan', 'th·∫≠n',
        # Medical procedures
                'x√©t nghi·ªám', 'si√™u √¢m', 'x quang', 'mri', 'ct scan', 'n·ªôi soi',
                'ti√™m', 'vaccine', 'v·∫Øc xin', 'ph√≤ng ng·ª´a', 'kh√°m ƒë·ªãnh k·ª≥',
        # Pharmacies and medical stores
                'pharmacity', 'long ch√¢u', 'medicare', 'ph√≤ng thu·ªëc', 'nh√† thu·ªëc',
        # Specialties
                'tai m≈©i h·ªçng', 'da li·ªÖu', 'th·∫ßn kinh', 'c∆° x∆∞∆°ng kh·ªõp', 'ph·ª• khoa'
        ],
        'patterns': [
            r'b·ªánh vi·ªán\s+\w+', r'ph√≤ng kh√°m\s+\w+', r'kh√°m\s+\w+',
            r'mua thu·ªëc', r'pharmacity', r'long ch√¢u'
        ]
        },
        'education': {
        'keywords': [
        # Educational institutions
                'h·ªçc', 'tr∆∞·ªùng', 's√°ch', 'kh√≥a h·ªçc', 'l·ªõp h·ªçc', 'gi√°o d·ª•c', 'ƒë√†o t·∫°o',
                'ƒë·∫°i h·ªçc', 'cao ƒë·∫≥ng', 'trung h·ªçc', 'ti·ªÉu h·ªçc', 'm·∫ßm non',
        # Subjects and skills
                'ti·∫øng anh', 'ti·∫øng nh·∫≠t', 'ti·∫øng trung', 'tin h·ªçc', 'k·∫ø to√°n', 'marketing',
                'l√°i xe', 'n·∫•u ƒÉn', 'may v√°', 'c·∫Øt t√≥c', 'nail', 'makeup',
        # Education companies
                'ila', 'apollo', 'acet', 'apax', 'smartkids', 'ames', 'yola',
        # Materials and fees
                'h·ªçc ph√≠', 's√°ch gi√°o khoa', 'v·ªü', 'b√∫t', 'c·∫∑p s√°ch', 'ƒë·ªìng ph·ª•c'
        ],
        'patterns': [
            r'h·ªçc\s+\w+', r'tr∆∞·ªùng\s+\w+', r'kh√≥a h·ªçc\s+\w+',
            r'ti·∫øng\s+\w+', r'h·ªçc ph√≠', r's√°ch\s+\w+'
        ]
        },
        'income': {
        'keywords': [
        # Salary and wages
                'l∆∞∆°ng', 'ti·ªÅn l∆∞∆°ng', 'th∆∞·ªüng', 'thu nh·∫≠p', 'salary', 'wage', 'bonus',
                'ti·ªÅn c√¥ng', 'c√¥ng vi·ªác', 'l√†m vi·ªác', 'l√†m th√™m', 'part time', 'full time',
        # Business income
                'b√°n h√†ng', 'kinh doanh', 'bu√¥n b√°n', 'doanh thu', 'l·ª£i nhu·∫≠n', 'hoa h·ªìng',
                'commission', 'affiliate', 'freelance', 't·ª± do',
        # Other income sources
                'ƒë·∫ßu t∆∞', 'c·ªï t·ª©c', 'l√£i su·∫•t', 'cho thu√™', 'b·∫•t ƒë·ªông s·∫£n',
                'giao h√†ng', 'shipper', 'grab driver', 'uber', 'be driver'
        ],
        'patterns': [
            r'l∆∞∆°ng\s+th√°ng', r'th∆∞·ªüng\s+\w+', r'ti·ªÅn\s+\w+',
            r'b√°n\s+\w+', r'thu\s+nh·∫≠p', r'l√†m\s+th√™m'
        ]
        }
        }

        # Initialize TF-IDF vectorizer for text similarity
        self.vectorizer = TfidfVectorizer(
        max_features=5000,
        stop_words=None, # No built-in Vietnamese stopwords
        ngram_range=(1, 3),
        analyzer='word'
        )

        self.classifier = MultinomialNB()
        self.is_trained = False

    def preprocess_text(self, text: str) -> str:
        """
        Preprocess Vietnamese text

        Args:
        text: Raw Vietnamese text

        Returns:
        Preprocessed text
        """
        # Convert to lowercase
        text = text.lower()

        # Tokenize using PyVi if available
        if PYVI_AVAILABLE:
        try:
        text = ViTokenizer.tokenize(text)
        except:
        pass # Fall back to original text if tokenization fails

        # Remove extra whitespace
        text = ' '.join(text.split())

        return text

    def extract_features(self, description: str) -> Dict[str, Any]:
        """
        Extract features from Vietnamese transaction description

        Args:
        description: Transaction description

        Returns:
        Feature dictionary
        """
        description_lower = description.lower()
        features = {}

        # Keyword matching features
        for category, data in self.vietnamese_categories.items():
        keyword_matches = 0
        pattern_matches = 0

        # Count keyword matches
        for keyword in data['keywords']:
        if keyword in description_lower:
        keyword_matches += 1

        # Count pattern matches
        for pattern in data.get('patterns', []):
        matches = len(re.findall(pattern, description_lower))
        pattern_matches += matches

        features[f'{category}_keywords'] = keyword_matches
        features[f'{category}_patterns'] = pattern_matches
        features[f'{category}_total'] = keyword_matches + pattern_matches

        # Text length features
        features['text_length'] = len(description)
        features['word_count'] = len(description.split())

        # Number detection
        numbers = re.findall(r'\d+', description)
        features['number_count'] = len(numbers)
        features['has_large_number'] = any(int(num) > 1000 for num in numbers if num.isdigit())

        return features

    def classify_transaction(self, description: str) -> Dict[str, Any]:
        """
        Classify Vietnamese transaction description

        Args:
        description: Vietnamese transaction description

        Returns:
        Dictionary with classification results
        """
        # Preprocess text
        processed_text = self.preprocess_text(description)

        # Extract features
        features = self.extract_features(description)

        # Calculate category scores
        category_scores = {}

        for category in self.vietnamese_categories.keys():
        # Get total matches for this category
        total_score = features.get(f'{category}_total', 0)
        keyword_score = features.get(f'{category}_keywords', 0)
        pattern_score = features.get(f'{category}_patterns', 0)

        # Normalize by category keyword count
        max_keywords = len(self.vietnamese_categories[category]['keywords'])
        max_patterns = len(self.vietnamese_categories[category].get('patterns', []))

        # Calculate normalized scores
        keyword_norm = keyword_score / max_keywords if max_keywords > 0 else 0
        pattern_norm = pattern_score / max_patterns if max_patterns > 0 else 0

        # Combined score with weights
        combined_score = (keyword_norm * 0.7) + (pattern_norm * 0.3)

        category_scores[category] = {
        'score': combined_score,
        'keyword_matches': keyword_score,
        'pattern_matches': pattern_score,
        'keyword_norm': keyword_norm,
        'pattern_norm': pattern_norm
        }

        # Find best category
        best_category = max(category_scores.keys(), key=lambda k: category_scores[k]['score'])
        confidence = category_scores[best_category]['score']

        # If confidence is too low, classify as 'other'
        if confidence < 0.1:
        best_category = 'other'
        confidence = 0.5

        return {
        'predicted_category': best_category,
        'confidence': confidence,
        'all_scores': category_scores,
        'features': features,
        'method': 'vietnamese_nlp_simple'
        }

    def extract_financial_entities(self, description: str) -> Dict[str, Any]:
        """
        Extract financial entities from Vietnamese text

        Args:
        description: Transaction description

        Returns:
        Extracted entities
        """
        entities = {
        'amounts': [],
        'merchants': [],
        'locations': [],
        'payment_methods': [],
        'times': []
        }

        # Extract amounts (Vietnamese currency patterns)
        amount_patterns = [
            r'(\d{1,3}(?:\.\d{3})*(?:\,\d+)?)\s*(?:k|K|ƒë|vnd|VND|ngh√¨n)',
            r'(\d+(?:\.\d+)?)\s*(?:tri·ªáu|t·ª∑)',
            r'(\d+)\s*(?:k|K)(?:\s|$|[^\w])',
        ]

        for pattern in amount_patterns:
        matches = re.findall(pattern, description, re.IGNORECASE)
        entities['amounts'].extend(matches)

        # Extract merchants and shops
        merchant_patterns = [
            r'(?:qu√°n|shop|c·ª≠a h√†ng|si√™u th·ªã|ch·ª£)\s+([A-Z√Ä-·ª∏][a-z√†-·ªπ\s]*)',
            r'([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\s+(?:store|shop|mart)',
            r'(vinmart|circle\s*k|gs\d+|pharmacity|long ch√¢u|cgv|lotte)',
        ]

        for pattern in merchant_patterns:
        matches = re.findall(pattern, description, re.IGNORECASE)
        entities['merchants'].extend(matches)

        # Extract Vietnamese locations
        vietnam_locations = [
            'h√† n·ªôi', 'tp.hcm', 's√†i g√≤n', 'ƒë√† n·∫µng', 'h·∫£i ph√≤ng', 'c·∫ßn th∆°',
            'hu·∫ø', 'nha trang', 'ƒë√† l·∫°t', 'v≈©ng t√†u', 'quy nhon', 'bu√¥n ma thu·ªôt',
            'qu·∫≠n 1', 'qu·∫≠n 2', 'qu·∫≠n 3', 'qu·∫≠n 4', 'qu·∫≠n 5', 'qu·∫≠n 6', 'qu·∫≠n 7',
            'qu·∫≠n 8', 'qu·∫≠n 9', 'qu·∫≠n 10', 'qu·∫≠n 11', 'qu·∫≠n 12', 'th·ªß ƒë·ª©c',
            'ba ƒë√¨nh', 'ho√†n ki·∫øm', 'ƒë·ªëng ƒëa', 'hai b√† tr∆∞ng', 'ho√†ng mai',
            'long bi√™n', 't√¢y h·ªì', 'c·∫ßu gi·∫•y', 'thanh xu√¢n', 'h√† ƒë√¥ng',
            'li√™n chi·ªÉu', 'h·∫£i ch√¢u', 's∆°n tr√†', 'ng≈© h√†nh s∆°n', 'c·∫©m l·ªá'
        ]

        for location in vietnam_locations:
        if location in description.lower():
        entities['locations'].append(location)

        # Extract payment methods
        payment_methods = [
            'grab', 'momo', 'zalopay', 'vnpay', 'viettel pay', 'airpay',
            'cash', 'ti·ªÅn m·∫∑t', 'th·∫ª', 'card', 'visa', 'mastercard',
            'chuy·ªÉn kho·∫£n', 'banking', 'atm'
        ]

        for method in payment_methods:
        if method in description.lower():
        entities['payment_methods'].append(method)

        # Extract time references
        time_patterns = [
            r'th√°ng\s+(\d{1,2})',
            r'(\d{1,2})/(\d{1,2})',
            r'(h√¥m nay|h√¥m qua|tu·∫ßn n√†y|th√°ng n√†y)',
        ]

        for pattern in time_patterns:
        matches = re.findall(pattern, description, re.IGNORECASE)
        entities['times'].extend(matches)

        return entities

    def train_classifier(self, transactions: List[Dict]):
        """
        Train the classifier on transaction data

        Args:
        transactions: List of labeled transactions
        """
        logger.info(f" Training classifier on {len(transactions)} transactions...")

        # Prepare training data
        texts = []
        labels = []

        for transaction in transactions:
        text = self.preprocess_text(transaction.get('description', ''))
        texts.append(text)
        labels.append(transaction.get('category', 'other'))

        # Fit vectorizer and classifier
        X = self.vectorizer.fit_transform(texts)
        self.classifier.fit(X, labels)
        self.is_trained = True

        logger.info(" Classifier training completed!")

    def process_transaction_batch(self, transactions: List[Dict]) -> List[Dict]:
        """
        Process a batch of transactions

        Args:
        transactions: List of transaction dictionaries

        Returns:
        Processed transactions with classifications
        """
        logger.info(f"üîÑ Processing batch of {len(transactions)} transactions...")

        processed = []
        for i, transaction in enumerate(transactions):
        if i % 1000 == 0 and i > 0:
        logger.info(f" Processed {i}/{len(transactions)} transactions")

        description = transaction.get('description', '')

        # Classify transaction
        classification = self.classify_transaction(description)

        # Extract entities
        entities = self.extract_financial_entities(description)

        # Add to transaction
        processed_transaction = transaction.copy()
        processed_transaction.update({
        'ai_category': classification['predicted_category'],
        'ai_confidence': classification['confidence'],
        'ai_scores': classification['all_scores'],
        'extracted_entities': entities,
        'processed_timestamp': datetime.now().isoformat(),
        'processor_version': 'simple_nlp_v1.0'
        })

        processed.append(processed_transaction)

        logger.info(f" Batch processing completed!")
        return processed

    def test_processor():
        """Test the Vietnamese NLP processor"""
        logger.info(" Testing Vietnamese NLP Processor...")

        # Initialize processor
        processor = SimpleVietnameseNLPProcessor()

        # Test transactions
        test_transactions = [
        {"description": "Qu√°n ph·ªü H√πng - Ph·ªü b√≤ t√°i 75k", "amount": 75000},
            {"description": "Grab t·ª´ H√† N·ªôi ƒëi H√† ƒê√¥ng 120k", "amount": 120000},
                {"description": "Vinmart+ C·∫ßu Gi·∫•y - Mua s·∫Øm th·ª±c ph·∫©m 350k", "amount": 350000},
                    {"description": "L∆∞∆°ng th√°ng 12 c√¥ng ty ABC 15000k", "amount": 15000000},
                        {"description": "Ti·ªÅn ƒëi·ªán EVN HANOI th√°ng 11 - 450k", "amount": 450000},
                            {"description": "CGV Vincom B√† Tri·ªáu - Xem phim Avatar 180k", "amount": 180000},
                                {"description": "Pharmacity Nguy·ªÖn Tr√£i - Mua thu·ªëc c·∫£m 85k", "amount": 85000},
                                    {"description": "ILA English Thanh Xu√¢n - H·ªçc ph√≠ th√°ng 12", "amount": 2500000},
                                        {"description": "Karaoke Nice Time - Ca h√°t v·ªõi b·∫°n b√® 320k", "amount": 320000},
                                            {"description": "Circle K L√°ng H·∫° - Mua n∆∞·ªõc v√† snack 45k", "amount": 45000}
                                            ]

        # Test classification
        print("\n" + "="*80)
        print(" VIETNAMESE TRANSACTION CLASSIFICATION RESULTS")
        print("="*80)

        for transaction in test_transactions:
        result = processor.classify_transaction(transaction['description'])
        entities = processor.extract_financial_entities(transaction['description'])

                                        print(f"\n Transaction: {transaction['description']}")
                                            print(f"üè∑ Category: {result['predicted_category']} (confidence: {result['confidence']:.3f})")
                                                print(f" Amount: {transaction['amount']:,} VND")
                                                    print(f" Entities: {entities}")

        # Show top 3 category scores
        sorted_scores = sorted(result['all_scores'].items(),
        key=lambda x: x[1]['score'], reverse=True)[:3]
        print(f" Top scores:")
        for cat, score_info in sorted_scores:
                                                        print(f" {cat}: {score_info['score']:.3f} (kw:{score_info['keyword_matches']}, pat:{score_info['pattern_matches']})")

        print("\n" + "="*80)
        logger.info(" Testing completed successfully!")

        if __name__ == "__main__":
        test_processor()